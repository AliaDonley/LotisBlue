##using mapdamage on aligned reads to assess if aDNA is legit or contaminated. Data needs to be filtered before before 
##being run through md to eliminate noise. Using mapfork to parrellelize in perl script


NEED TO FILTER OFF ENDS FIRSt
All in: /scratch/general/nfs1/u6000989/LycLotis/

cp FilterFork.pl 


file="/scratch/general/nfs1/u6000989/LycLotis/dedup_BAT20.bam"
output="/scratch/general/nfs1/u6000989/LycLotis/filtered_dedup_BAT20.bam"
samtools view -h "$file" | awk 'length($10) >= 50 || $1 ~ /^@/' | samtools view -Sb - > "$output"
            ###samtools view h file- for the computer to read the file and h ensures the header of the bam is included in the output
            ###| awk 'length($10) >= 50 || $1 ~ /^@/' | pipeline (output is used as next input)
            ### 10 is the 10th field (sequence of the read in this case, aligned to the reference) and checking for reads larger than 50bp
            ###  $1 ~ /^@/'- keeps all lines that start with @ (headers) in sam file. ^@ ensures header info is preserved
module load samtools
perl FilterFork.pl dedup_*bam

MapDamFork.pl
#!/usr/bin/perl
#
# run mapdamage
#
perl MapDamFork.pl *filtered_*.bamjob

use Parallel::ForkManager;
my $max = 12;
my $pm = Parallel::ForkManager->new($max);

foreach $file (@ARGV){
        $pm->start and next; ## fork
        $file =~ m/_([a-zA-Z0-9]+)\.bam/;
        $id = $1;
        $out = "output_$id"."_result";
        print "mapDamage -i $file -r ~/../gompert-group3/data/LmelGenome/Lmel_dovetailPacBio_genome.fasta -d $out\n";
        system "mapDamage -i $file -r ~/../gompert-group3/data/LmelGenome/Lmel_dovetailPacBio_genome.fasta -d $out\n";
        $pm->finish;
}
$pm->wait_all_children;


then:

#!/bin/sh
#SBATCH --time=72:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --account=gompert
#SBATCH --partition=kingspeak
#SBATCH --job-name=Lotismapdamagefiltered
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alia.donley@usu.edu

cd /uufs/chpc.utah.edu/common/home/u6047808/LycLotis/00_Alignment/01_mapdamage

perl MapDamFork.pl /scratch/general/nfs1/u6000989/LycLotis/*bam


###using ngsutils bamutils filter to refilter bams because filtering after mapdamage truncated the files
##local install from chpc people, downloaded on via conda too (probaboly didn't need to)

module load ngsutils
bamutils (command)
bamutils filter, minlen, mapped, etc

##to test one
bamutils filter dedup_BATasdad20.bam filtered_BAT20.bam -mapped -minlen 50
bamutils filter dedup_LOTIS.bam filtered_LOTIS.bam -mapped -minlen 50


##to parellelize 
FilteredEndReads.pl

#!/usr/bin/perl
#
# filter mapdamage reads (in Zachs LycLotis)
#
##use .sh script to submit as batch job



use Parallel::ForkManager;
my $max = 12;
my $pm = Parallel::ForkManager->new($max);

foreach $file (@ARGV){
        $pm->start and next; ## fork
        $file =~ m/_([a-zA-Z0-9]+)\.bam/;
        $id = $1;
        $out = "output_$id"."_filtered.bam";
        print "bamutils filter $file $out -mapped -minlen 50\n";
        system "bamutils filter $file $out -mapped -minlen 50\n";
        $pm->finish;
}
$pm->wait_all_children;

###sh script for submission:
(base) [u6047808@kingspeak2:LycLotis]$ cat RunFilter.sh 
#!/bin/sh
#SBATCH --time=48:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --account=gompert
#SBATCH --partition=kingspeak
#SBATCH --job-name=filter
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alia.donley@usu.edu

module load ngsutils

cd /scratch/general/nfs1/u6000989/LycLotis

perl FilterEndReads.pl dedup_*bam

##filtered mapdamage run did not have filtered data. check what is in the files, convert BAM to SAM and compare 
##filtered and unfiltered files. If all checks out, just run one, line by line

##Decided mapdamage was mislabelling x-axis (read length) and instead we need to find the differentiation between 
##soft-clipped reads and bases between filtered samples. 




To check what is in the files:
samtools view output_LOTIS_filtered.bam | awk '{print length($10)}' | sort | uniq -c
samtools view dedup_LOTIS.bam | awk '{print length($10)}' | sort | uniq -c
samtools flagstat output_LOTIS_filtered.bam
samtools flagstat dedup_LOTIS.bam
## this confirmed that filtering did indeed work
## now we need to find how many soft clipped bases vs soft clipped reads we have
To convert BAM to SAM:

samtools view -h -o outputSAMLotis.sam output_LOTIS_filtered.bam
samtools view -h -o outputdedupSAMLotis.sam dedup_LOTIS.bam

To parallelize them: Sam2Bam.pl (really Bam to Sam lol)
Ran it interactively. To run as a batch job make .sh script. 

#!/usr/bin/perl
#
# alignment with bwa mem 
#
use Parallel::ForkManager;
my $max = 30;
my $pm = Parallel::ForkManager->new($max);

FILES:
foreach $bam (@ARGV){
        $pm->start and next FILES; ## fork
        $out = $bam;
        $out =~ s/bam/sam/ or die "failed sub here: $out\n";
        system "samtools view -h -o $out $bam\n";
        $pm->finish;
}

$pm->wait_all_children;

##Zach wrote a perl script to count soft clipped info
CountSoftClip.pl
## Have a .sh script to run job as a batch job

Softclip.sh
#!/bin/sh
#SBATCH --time=72:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=30
#SBATCH --account=gompert
#SBATCH --partition=kingspeak
#SBATCH --job-name=Softclip
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alia.donley@usu.edu


module load perl
cd /scratch/general/nfs1/u6000989/LycLotis

for file in output_*filtered.sam; do
        output="${file%.sam}.txt" ##sam to txt for the output
        perl CountSoftClip.pl $file > $output
done














chaimaric reads..? if nothing on that first mode inclined to get rid of them to eliminate noise. can bamutils filter based on cigar string. if not find one or write script using samtools..?
soft clipping short fragments- trust them or get them out?
variant call- maybe redo if getting rid of short fragments
filter snps using perl to 
filter to get rid of ga and ct snps 




find euphiloites genome close as i can get- turned out to be Alexis. Making own ref?


